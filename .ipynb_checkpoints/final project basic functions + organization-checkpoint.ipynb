{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizational Goals for Project and Basic Data Cleaning Functions:\n",
    "\n",
    "Ideally, you should only have to tell a script a few things in order to get stuff like:\n",
    "   - Merged dataframes\n",
    "   - Dataframe without outliers\n",
    "   - Basic plots\n",
    "   - Basic stats\n",
    "\n",
    "If you tell the script things like 'relevant columns', you should be able to output dataframes that only have variables of interest.\n",
    "\n",
    "We can create one function to read in both kinds of data (beh/eye), but will need separate functions for cleaning the data.\n",
    "\n",
    "Here's an example of the only things that should be hard-coded in the final script(s), ideally in a cell right at the top of the notebook:\n",
    "- current folder directory\n",
    "    - or multiple, say if you have some for data and another for outputs\n",
    "- txt file names:\n",
    "    - a file for new column names\n",
    "    - a file for columns to filter\n",
    "- the independent variables of interest (list of strings is fine)\n",
    "- the dependent variables of interest ('')\n",
    "- probably a few other things but haven't gotten there yet!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic functions for data processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import_all_csvs: reads in all CSVs in a folder and compiles them into one dataframe\n",
    "- required packages: pandas, glob\n",
    "- inputs: folder directory\n",
    "- outputs: new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fc85180eed51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# master_df = import_all_csvs('/Users/elizabethpierotti/Desktop/Kids Auditory N4/data/interim')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmaster_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_all_csvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/elizabethpierotti/Desktop/school/python/final project/data/psycho_py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# master_df = import_all_csvs('/Users/elizabethpierotti/Desktop/Kids Auditory N4/data/behavioral')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-fc85180eed51>\u001b[0m in \u001b[0;36mimport_all_csvs\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimport_all_csvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/*.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmaster_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "    \n",
    "def import_all_csvs(folder): \n",
    "    files = glob(folder + '/*.csv')\n",
    "    master_df = pd.concat([pd.read_csv(f) for f in files ])\n",
    "    return master_df   \n",
    "\n",
    "# test cases:\n",
    "# master_df = import_all_csvs('/Users/elizabethpierotti/Desktop/school/python/pandas_story_telling/data/raw')\n",
    "# master_df = import_all_csvs('/Users/elizabethpierotti/Desktop/Kids Auditory N4/data/interim')\n",
    "\n",
    "master_df = import_all_csvs('/Users/elizabethpierotti/Desktop/school/python/final project/data/psycho_py')\n",
    "# master_df = import_all_csvs('/Users/elizabethpierotti/Desktop/Kids Auditory N4/data/behavioral')\n",
    "\n",
    "master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter columns: reads in .txt file w column names to keep and makes a new df with only those columns\n",
    "- required packages: pandas\n",
    "- inputs: relevant columns .txt file, dataframe to edit columns\n",
    "    - NOTE: the .txt file should have each col name on a new line\n",
    "- outputs: filtered dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_columns(txt_file, df):\n",
    "    file = open(txt_file,'r')\n",
    "    cols = file.readlines()\n",
    "    names = [col.strip('\\n') for col in cols ]\n",
    "    filtered_df = pd.DataFrame()\n",
    "    for name in names:\n",
    "        if name in df.columns:\n",
    "            rel_col = df[[name]]\n",
    "            filtered_df[[name]]= rel_col  \n",
    "    return filtered_df\n",
    "\n",
    "# test case:\n",
    "curr_folder = '/Users/elizabethpierotti/Desktop/Kids Auditory N4/data/behavioral'    \n",
    "rel_col_file = curr_folder + '/relevant_cols.txt'  \n",
    "filter_columns(rel_col_file, master_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rename_columns: reads in .txt file w new column names and replaces column names in current df\n",
    "- required packages: pandas\n",
    "- inputs: column name .txt file, dataframe to edit columns\n",
    "    - NOTE: the .txt file should have each col name on a new line\n",
    "- outputs: new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def rename_columns(txt_file, df):\n",
    "    file = open(txt_file,'r')\n",
    "    cols = file.readlines()\n",
    "    names = [col.strip('\\n') for col in cols ]\n",
    "    # if there are extra columns at the end that you don't want, this cuts them off:\n",
    "    if len(df.columns) == len(names):\n",
    "        df.columns = names\n",
    "    else:\n",
    "        df = df.iloc[:,0:(len(names))]\n",
    "        df.columns = names\n",
    "    return df\n",
    "    \n",
    "# test case:\n",
    "curr_folder = '/Users/elizabethpierotti/Desktop/Kids Auditory N4/data/behavioral'    \n",
    "rename_col_file = curr_folder + '/new_cols.txt'  \n",
    "newnames_df = rename_columns(rename_col_file, master_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subject_accuracy: using two specified columns (correct and incorrect), calculates accuracy and adds a column for these values\n",
    "- required packages: \n",
    "- inputs: df, correct column name (or index?), incorrect column name\n",
    "- outputs: new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove_outliers: given a df and a variable to act on, calculate IQR and identify values that exceed  it. Then return df without these values.\n",
    "- required packages: stats/iqr\n",
    "- inputs: df, variable of interest\n",
    "- outputs: new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5670, 32)\n",
      "(5510, 32)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import iqr\n",
    "\n",
    "def remove_outliers(df, var, outlier_constant = 1.5):\n",
    "    IQR = iqr(df[var].dropna())\n",
    "    outliers = IQR*outlier_constant\n",
    "    lowerOutliersCalc = (df[var].quantile([.25])) - outliers\n",
    "    upperOutliersCalc = (df[var].quantile([.75])) + outliers\n",
    "    lowerOutliers = lowerOutliersCalc.iloc[0]\n",
    "    upperOutliers = upperOutliersCalc.iloc[0]\n",
    "    cleanTrials = df[df[var].between(lowerOutliers, upperOutliers)]\n",
    "    return(cleanTrials)     \n",
    "\n",
    "# test case:\n",
    "#curr_folder = '/Users/elizabethpierotti/Desktop/Kids Auditory N4/data/processed'    \n",
    "#f = curr_folder + '/poster_data.csv' \n",
    "#poster_data = pd.read_csv(f)\n",
    "#clean_df = remove_outliers(poster_data, 'MNA')\n",
    "\n",
    "#print(poster_data.shape)\n",
    "#print(clean_df.shape)\n",
    "\n",
    "clean_df = remove_outliers(master_df, 'key_resp_2.rt')\n",
    "print(master_df.shape)\n",
    "print(clean_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(MSD_eye, MSD_behavioral, on =['trial', 'participant'], how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create CSV of Finalized Data\n",
    "merged_df.to_csv(curr_folder + '/processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
